{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the main notebook used to generate training/validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as data\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import create_dataset\n",
    "\n",
    "import json\n",
    "import unicodedata\n",
    "import string\n",
    "import itertools\n",
    "import bisect\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_directory = os.path.expanduser('~')\n",
    "nn_library_path = home_directory + '/Documents/HarveyMuddWork/Neural_Nets_Research/neural_nets_research/neural_nets_library'\n",
    "sys.path.append(nn_library_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import greyscale_image_loader, tightest_image_crop, square_padding, vertical_scale_preserve_aspect_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    npimg = np.asarray(img)\n",
    "    plt.figure()\n",
    "    plt.imshow(npimg, interpolation='nearest', cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def overlap_concat(img1, img2, overlap_amt):\n",
    "    left = img1[:,0:len(img1[0]) - overlap_amt]\n",
    "    mid = img1[:,len(img1[0])-overlap_amt : len(img1[0])] + img2[:, 0:overlap_amt]\n",
    "    values, counts = np.unique(mid, return_counts=True)\n",
    "    values = list(values)\n",
    "    overlapping = 0\n",
    "    \n",
    "    if 254 in values:\n",
    "        overlapping = counts[values.index(254)]\n",
    "    right = img2[:,overlap_amt:]\n",
    "\n",
    "    return np.concatenate((left, mid, right), axis = 1), overlapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_concat(img1, img2, max_over):    \n",
    "    for i in range(1, min(len(img1[0]), len(img2[0]))):\n",
    "        new, overlap = overlap_concat(img1, img2, i)\n",
    "        if overlap >= max_over:\n",
    "            if i == 1:\n",
    "                new, _ = overlap_concat(img1, img2, i)\n",
    "            else:\n",
    "                slide_back = random.randrange(1, 10)\n",
    "                overlap = max(1, i - slide_back)\n",
    "                new, _ = overlap_concat(img1, img2, overlap)\n",
    "            return new\n",
    "        \n",
    "    if max_over != 1:\n",
    "        return get_concat(img1, img2, 1)\n",
    "    else:\n",
    "        return overlap_concat(img1, img2, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def np_tightest_image_crop(img):\n",
    "    image_indices = img.nonzero()\n",
    "    image_indices = np.array(list(zip(image_indices[0], image_indices[1])))\n",
    "\n",
    "    top_i = image_indices[0,0]\n",
    "    bottom_i = image_indices[-1,0]\n",
    "    \n",
    "    mins = image_indices.min(axis=0)\n",
    "    left_i = mins[1]\n",
    "    \n",
    "    maxs = image_indices.max(axis=0)\n",
    "    right_i = maxs[1]\n",
    "    \n",
    "    new_width = right_i-left_i+1\n",
    "    new_height = top_i-bottom_i+1\n",
    "        \n",
    "    return img[top_i:bottom_i+1, left_i:right_i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def choices(elements, probabilities):\n",
    "    cumdist = list(itertools.accumulate(probabilities))\n",
    "    return elements[bisect.bisect(cumdist, random.random())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0,
     15,
     24,
     37
    ]
   },
   "outputs": [],
   "source": [
    "def add_random_dot(img):\n",
    "    dot = np.zeros_like(img)\n",
    "    height, width = img.shape\n",
    "    hDot, wDot = random.randrange(height-5, height), random.randrange(width - 5, width)\n",
    "    dot[hDot, wDot] = random.random() * 100 + 50\n",
    "    \n",
    "    dot = gaussian_filter(dot, 5)\n",
    "    \n",
    "    dot[dot < 0.5] = 0\n",
    "    dot[dot > 0.5] = 1\n",
    "    dot[np.logical_and(dot, img)] = 0\n",
    "    dot = dot.astype('uint8')\n",
    "    \n",
    "    return img + dot*np.amax(img)\n",
    "\n",
    "def close_to_line_segment(tolerance, x_mid, y_mid, slope, length_squared):\n",
    "    def close_to_line_segment2(x, y):\n",
    "        result = np.ones_like(x)\n",
    "        result[(x - x_mid)**2 + (y - y_mid)**2 > length_squared] = 0\n",
    "        result[abs((x - x_mid) * slope + y_mid - y) > tolerance] = 0\n",
    "        return result\n",
    "        \n",
    "    return close_to_line_segment2\n",
    "\n",
    "def add_random_line(img):\n",
    "    tolerance = random.randrange(3) + 0.1\n",
    "    height, width = img.shape\n",
    "    x_mid, y_mid = random.randrange(height), random.randrange(width)\n",
    "    slope = (random.random() - 0.5) * 10\n",
    "    length_squared = random.randrange(4,10) ** 2\n",
    "    line = np.fromfunction(close_to_line_segment(tolerance, x_mid, y_mid, slope, length_squared), \n",
    "                                 (height, width), dtype='uint8')\n",
    "    line[np.logical_and(line, img)] = 0\n",
    "    \n",
    "    return img + line*np.amax(img)\n",
    "    \n",
    "# Image should be a numpy array.\n",
    "def add_noise(img):\n",
    "    noise_prob_dist = [0.75, 0.15, 0.05, 0.05]\n",
    "    amount_of_noise = choices(range(4), noise_prob_dist)\n",
    "    \n",
    "    for _ in range(amount_of_noise):\n",
    "        if random.random() < 0.5:\n",
    "            img = add_random_dot(img)\n",
    "        else:\n",
    "            img = add_random_line(img)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": [
     140,
     184
    ]
   },
   "outputs": [],
   "source": [
    "class TextDataset(object):\n",
    "    def __init__(self, word_dictionary, image_folder_names,\n",
    "                 number_of_training_data_points=500000, number_of_validation_data_points=10000, \n",
    "                 number_prob=0.5, deskewed=True, noise=True, seed=1000, variation_characters=None):\n",
    "        self.training_img_paths = []\n",
    "        self.training_text_labels = []\n",
    "        \n",
    "        self.validation_img_paths = []\n",
    "        self.validation_text_labels = []\n",
    "        self.tuple_mode = {}\n",
    "        \n",
    "        possible_num_digits = [1, 2, 3, 4, 5]\n",
    "        num_digit_dist = [0.02, 0.2, 0.6, 0.1, 0.08]\n",
    "        training_image_path_names = {}\n",
    "        validation_image_path_names = {}\n",
    "        \n",
    "        for key, folder_list in image_folder_names.items():\n",
    "            training_image_path_names[key] = []\n",
    "            validation_image_path_names[key] = []\n",
    "            \n",
    "            for folder in folder_list:\n",
    "                if isinstance(folder, tuple):\n",
    "                    self.tuple_mode[key] = True\n",
    "                    prob, folder_name = folder\n",
    "                    image_paths = list(map(lambda file: os.path.join(folder_name, file), \n",
    "                                           os.listdir(folder_name)))\n",
    "                    training_image_path_names[key].append((prob, image_paths[:int(0.8*len(image_paths))]))\n",
    "                    validation_image_path_names[key].append((prob, image_paths[int(0.8*len(image_paths)):]))\n",
    "                else:\n",
    "                    self.tuple_mode[key] = False\n",
    "                    image_paths = list(map(lambda file: os.path.join(folder, file), os.listdir(folder)))\n",
    "                    training_image_path_names[key].extend(image_paths[:int(0.8*len(image_paths))])\n",
    "                    validation_image_path_names[key].extend(image_paths[int(0.8*len(image_paths)):]) \n",
    "        \n",
    "        for i in range(number_of_training_data_points):\n",
    "            self.training_img_paths.append([])\n",
    "            \n",
    "            if random.random() < number_prob:\n",
    "                num_digits = choices(possible_num_digits, num_digit_dist)\n",
    "                number = str(random.randrange(10**(num_digits - 1), 10**num_digits - 1))\n",
    "                self.training_text_labels.append(number)\n",
    "                \n",
    "                for digit in number:\n",
    "                    if self.tuple_mode[digit]:\n",
    "                        probabilities = list(map(lambda pair: pair[0], training_image_path_names[digit]))\n",
    "                        folders = list(map(lambda pair: pair[1], training_image_path_names[digit]))\n",
    "                        folder_choice = choices(folders, probabilities)\n",
    "                        self.training_img_paths[i].append(random.choice(folder_choice))\n",
    "                    else:\n",
    "                        self.training_img_paths[i].append(random.choice(training_image_path_names[digit]))\n",
    "            else:\n",
    "                word = random.choice(word_dictionary)\n",
    "                self.training_text_labels.append(\"\")\n",
    "                                \n",
    "                for char in word:\n",
    "                    if variation_characters is not None:\n",
    "                        if random.random() < 0.5:\n",
    "                            char = variation_characters[char]\n",
    "                    \n",
    "                    if self.tuple_mode[char]:\n",
    "                        probabilities = list(map(lambda pair: pair[0], training_image_path_names[char]))\n",
    "                        folders = list(map(lambda pair: pair[1], training_image_path_names[char]))\n",
    "                        folder_choice = choices(folders, probabilities)\n",
    "                        self.training_img_paths[i].append(random.choice(folder_choice))\n",
    "                    else:\n",
    "                        self.training_img_paths[i].append(random.choice(training_image_path_names[char]))\n",
    "                        \n",
    "                    self.training_text_labels[i] += char\n",
    "        \n",
    "        for i in range(number_of_validation_data_points):\n",
    "            self.validation_img_paths.append([])\n",
    "            \n",
    "            if random.random() < number_prob:\n",
    "                num_digits = choices(possible_num_digits, num_digit_dist)\n",
    "                number = str(random.randrange(10**(num_digits - 1), 10**num_digits - 1))\n",
    "                self.validation_text_labels.append(number)\n",
    "                \n",
    "                for digit in number:\n",
    "                    if self.tuple_mode[digit]:\n",
    "                        probabilities = list(map(lambda pair: pair[0], validation_image_path_names[digit]))\n",
    "                        folders = list(map(lambda pair: pair[1], validation_image_path_names[digit]))\n",
    "                        folder_choice = choices(folders, probabilities)\n",
    "                        self.validation_img_paths[i].append(random.choice(folder_choice))\n",
    "                    else:\n",
    "                        self.validation_img_paths[i].append(random.choice(validation_image_path_names[digit]))\n",
    "            else:\n",
    "                word = random.choice(word_dictionary)\n",
    "                self.validation_text_labels.append(\"\")\n",
    "                                \n",
    "                for char in word:\n",
    "                    if variation_characters is not None:\n",
    "                        if random.random() < 0.5:\n",
    "                            char = variation_characters[char]\n",
    "                    \n",
    "                    if self.tuple_mode[char]:\n",
    "                        probabilities = list(map(lambda pair: pair[0], validation_image_path_names[char]))\n",
    "                        folders = list(map(lambda pair: pair[1], validation_image_path_names[char]))\n",
    "                        folder_choice = choices(folders, probabilities)\n",
    "                        self.validation_img_paths[i].append(random.choice(folder_choice))\n",
    "                    else:\n",
    "                        self.validation_img_paths[i].append(random.choice(validation_image_path_names[char]))\n",
    "                        \n",
    "                    self.validation_text_labels[i] += char\n",
    "                            \n",
    "        self.seed = seed\n",
    "        self.reset_seed()\n",
    "        \n",
    "        self.deskewed = deskewed\n",
    "        \n",
    "        if self.deskewed:\n",
    "            self.deskew_matrix = np.array([[1, 0, 0], [-0.51, 1, 32*0.51/2]])\n",
    "            \n",
    "        self.noise = noise\n",
    "                \n",
    "    def generate_words(self, output_folder, output_path, training=False):\n",
    "        if training:\n",
    "            num_images = len(self.training_img_paths)\n",
    "            labels = self.training_text_labels\n",
    "        else:\n",
    "            num_images = len(self.validation_img_paths)\n",
    "            labels = self.validation_text_labels\n",
    "                \n",
    "        for i in range(num_images):\n",
    "            image = self.generate_image(i, training)\n",
    "            image_name = str(i) + '.png'\n",
    "            image_path = os.path.join(output_folder, image_name)\n",
    "            image.save(image_path)\n",
    "        \n",
    "        def width_by_index(n):\n",
    "            image_name = str(n) + '.png'\n",
    "            image_path = os.path.join(output_folder, image_name)\n",
    "            image = greyscale_image_loader(image_path)\n",
    "            return image.size[0]\n",
    "        \n",
    "        images_by_width_index = sorted(range(num_images), key=width_by_index)        \n",
    "        image_paths_by_width = list(map(lambda n: os.path.join(output_folder, str(n) + '.png'), \n",
    "                                    images_by_width_index))\n",
    "        text_labels_by_width = list(map(lambda n: labels[n], images_by_width_index))\n",
    "        create_dataset.createDataset(output_path, image_paths_by_width, text_labels_by_width)\n",
    "          \n",
    "    def generate_image(self, i, training=False):\n",
    "        zero_padding = random.randrange(1,3)\n",
    "                \n",
    "        if training:\n",
    "            curr_img_paths = self.training_img_paths[i]\n",
    "        else:\n",
    "            curr_img_paths = self.validation_img_paths[i] \n",
    "        \n",
    "        img = greyscale_image_loader(curr_img_paths[0])\n",
    "        img = np.asarray(img)\n",
    "        img = np_tightest_image_crop(img)      \n",
    "        img = Image.fromarray(img)\n",
    "        img = vertical_scale_preserve_aspect_ratio(img, 32 - (2*zero_padding))\n",
    "        img = np.asarray(img)      \n",
    "        img = np.pad(img, zero_padding, 'constant', constant_values=0)\n",
    "        \n",
    "        if self.deskewed and 'SanbornDigits' in curr_img_paths[0]:\n",
    "            h, w = img.shape\n",
    "            img = cv2.warpAffine(img, self.deskew_matrix, (w,h), flags=cv2.INTER_NEAREST)\n",
    "        \n",
    "        rand_over = random.randrange(1,3)\n",
    "        \n",
    "        for j in range(1, len(curr_img_paths)):\n",
    "            img2 = greyscale_image_loader(curr_img_paths[j])\n",
    "            img2 = np.asarray(img2)\n",
    "            img2 = np_tightest_image_crop(img2)\n",
    "            img2 = Image.fromarray(img2)\n",
    "            img2 = vertical_scale_preserve_aspect_ratio(img2, 32 - (2*zero_padding))\n",
    "            img2 = np.asarray(img2)\n",
    "            img2 = np.pad(img2, zero_padding, 'constant', constant_values=0)\n",
    "            \n",
    "            if self.deskewed and 'SanbornDigits' in curr_img_paths[j]:\n",
    "                h, w = img2.shape\n",
    "                img2 = cv2.warpAffine(img2, self.deskew_matrix, (w,h), \n",
    "                                      flags=cv2.INTER_NEAREST)\n",
    "            \n",
    "            img = get_concat(img, img2, rand_over)\n",
    "\n",
    "        if self.noise:\n",
    "            img = add_noise(img)            \n",
    "\n",
    "        img = Image.fromarray(img)\n",
    "        return img\n",
    "    \n",
    "    def reset_seed(self):\n",
    "        random.seed(self.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     2,
     9
    ]
   },
   "outputs": [],
   "source": [
    "all_letters = string.ascii_letters\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "def make_dictionary(dictionary_file):\n",
    "    word_dictionary = []\n",
    "    \n",
    "    with open(dictionary_file) as dictionary:\n",
    "        for line in dictionary:\n",
    "            line = line.strip()\n",
    "            \n",
    "            if line.isalpha():\n",
    "                word_dictionary.append(unicodeToAscii(line).upper())\n",
    "    \n",
    "    return word_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_sanborn_char_folder_names = {'A': 'B10', 'B': 'B11', 'C': 'B12', 'D': 'B13', 'E': 'B14', \n",
    "                                 'F': 'B15', 'G': 'B16', 'H': 'B17', 'I': 'B18', 'J': 'B19', \n",
    "                                 'K': 'C20', 'L': 'C21', 'M': 'C22', 'N': 'C23', 'O': 'C24', \n",
    "                                 'P': 'C25', 'Q': 'C26', 'R': 'C27', 'S': 'C28', 'T': 'C29', \n",
    "                                 'U': 'D30', 'V': 'D31', 'W': 'D32', 'X': 'D33', 'Y': 'D34', \n",
    "                                 'Z': 'D35'}\n",
    "\n",
    "for c in string.ascii_uppercase:\n",
    "    not_sanborn_char_folder_names[c] = ['/home/mehdi2277/Documents/HarveyMuddWork/Clinic/by_class/' + not_sanborn_char_folder_names[c]]\n",
    "\n",
    "sanborn_char_folder_names = {}\n",
    "\n",
    "for c in string.ascii_uppercase:\n",
    "    sanborn_char_folder_names[c] = ['/media/mehdi2277/MyFiles/large_datasets/text_classification/labeled_letters/' + c]\n",
    "\n",
    "sanborn_digits = {}\n",
    "\n",
    "for i in range(10):\n",
    "    sanborn_digits[str(i)] = ['/media/mehdi2277/MyFiles/large_datasets/text_classification/SanbornDigits/' + str(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_sanborn_words = {}\n",
    "    \n",
    "for c in string.ascii_uppercase:\n",
    "    pure_sanborn_words[c] = sanborn_char_folder_names[c]\n",
    "    \n",
    "for i in range(10):\n",
    "    pure_sanborn_words[str(i)] = sanborn_digits[str(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_sanborn_words = {}\n",
    "\n",
    "for c in string.ascii_uppercase:\n",
    "    mixed_sanborn_words[c] = list(map(lambda folder_name: (0.5, folder_name), \n",
    "                                      sanborn_char_folder_names[c] +  not_sanborn_char_folder_names[c]))\n",
    "\n",
    "for i in range(10):\n",
    "    mixed_sanborn_words[str(i)] = sanborn_digits[str(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_variation_sanborn_words = {}\n",
    "\n",
    "for c in string.ascii_uppercase:\n",
    "    mixed_variation_sanborn_words[c] = sanborn_char_folder_names[c]\n",
    "    \n",
    "for c in string.ascii_lowercase:\n",
    "    mixed_variation_sanborn_words[c] = not_sanborn_char_folder_names[c.upper()]\n",
    "    \n",
    "for i in range(10):\n",
    "    mixed_variation_sanborn_words[str(i)] = sanborn_digits[str(i)]\n",
    "    \n",
    "mixed_variation_characters = {c: c.lower() for c in string.ascii_uppercase}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_rare_sanborn_words = {}\n",
    "\n",
    "for c in string.ascii_uppercase:\n",
    "    if c == 'J' or c == 'Q' or c == 'X' or c == 'Z':\n",
    "        mixed_rare_sanborn_words[c] = list(map(lambda folder_name: (0.5, folder_name), \n",
    "                                               sanborn_char_folder_names[c] +  \\\n",
    "                                               not_sanborn_char_folder_names[c]))\n",
    "    else:\n",
    "        mixed_rare_sanborn_words[c] = sanborn_char_folder_names[c]\n",
    "\n",
    "for i in range(10):\n",
    "    mixed_sanborn_words[str(i)] = sanborn_digits[str(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_rare_variation_sanborn_words = {}\n",
    "\n",
    "for c in string.ascii_uppercase:\n",
    "    mixed_rare_variation_sanborn_words[c] = sanborn_char_folder_names[c]\n",
    "    \n",
    "for c in string.ascii_lowercase:\n",
    "    if c == 'J' or c == 'Q' or c == 'X' or c == 'Z':\n",
    "        continue\n",
    "    \n",
    "    mixed_rare_variation_sanborn_words[c] = not_sanborn_char_folder_names[c.upper()]\n",
    "    \n",
    "for i in range(10):\n",
    "    mixed_rare_variation_sanborn_words[str(i)] = sanborn_digits[str(i)]\n",
    "\n",
    "mixed_rare_variation_characters = {}\n",
    "\n",
    "for c in string.ascii_uppercase:\n",
    "    if c == 'J' or c == 'Q' or c == 'X' or c == 'Z':\n",
    "        mixed_rare_variation_characters[c] = c\n",
    "    else:\n",
    "        mixed_rare_variation_characters[c] = c.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_word_dictionary = []\n",
    "dictionary_file = '/usr/share/dict/words'\n",
    "use_word_dictionary = make_dictionary(dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written 1000 / 500000\n",
      "Written 2000 / 500000\n",
      "Written 3000 / 500000\n",
      "Written 4000 / 500000\n",
      "Written 5000 / 500000\n",
      "Written 6000 / 500000\n",
      "Written 7000 / 500000\n",
      "Written 8000 / 500000\n",
      "Written 9000 / 500000\n",
      "Written 10000 / 500000\n",
      "Written 11000 / 500000\n",
      "Written 12000 / 500000\n",
      "Written 13000 / 500000\n",
      "Written 14000 / 500000\n",
      "Written 15000 / 500000\n",
      "Written 16000 / 500000\n",
      "Written 17000 / 500000\n",
      "Written 18000 / 500000\n",
      "Written 19000 / 500000\n",
      "Written 20000 / 500000\n",
      "Written 21000 / 500000\n",
      "Written 22000 / 500000\n",
      "Written 23000 / 500000\n",
      "Written 24000 / 500000\n",
      "Written 25000 / 500000\n",
      "Written 26000 / 500000\n",
      "Written 27000 / 500000\n",
      "Written 28000 / 500000\n",
      "Written 29000 / 500000\n",
      "Written 30000 / 500000\n",
      "Written 31000 / 500000\n",
      "Written 32000 / 500000\n",
      "Written 33000 / 500000\n",
      "Written 34000 / 500000\n",
      "Written 35000 / 500000\n",
      "Written 36000 / 500000\n",
      "Written 37000 / 500000\n",
      "Written 38000 / 500000\n",
      "Written 39000 / 500000\n",
      "Written 40000 / 500000\n",
      "Written 41000 / 500000\n",
      "Written 42000 / 500000\n",
      "Written 43000 / 500000\n",
      "Written 44000 / 500000\n",
      "Written 45000 / 500000\n",
      "Written 46000 / 500000\n",
      "Written 47000 / 500000\n",
      "Written 48000 / 500000\n",
      "Written 49000 / 500000\n",
      "Written 50000 / 500000\n",
      "Written 51000 / 500000\n",
      "Written 52000 / 500000\n",
      "Written 53000 / 500000\n",
      "Written 54000 / 500000\n",
      "Written 55000 / 500000\n",
      "Written 56000 / 500000\n",
      "Written 57000 / 500000\n",
      "Written 58000 / 500000\n",
      "Written 59000 / 500000\n",
      "Written 60000 / 500000\n",
      "Written 61000 / 500000\n",
      "Written 62000 / 500000\n",
      "Written 63000 / 500000\n",
      "Written 64000 / 500000\n",
      "Written 65000 / 500000\n",
      "Written 66000 / 500000\n",
      "Written 67000 / 500000\n",
      "Written 68000 / 500000\n",
      "Written 69000 / 500000\n",
      "Written 70000 / 500000\n",
      "Written 71000 / 500000\n",
      "Written 72000 / 500000\n",
      "Written 73000 / 500000\n",
      "Written 74000 / 500000\n",
      "Written 75000 / 500000\n",
      "Written 76000 / 500000\n",
      "Written 77000 / 500000\n",
      "Written 78000 / 500000\n",
      "Written 79000 / 500000\n",
      "Written 80000 / 500000\n",
      "Written 81000 / 500000\n",
      "Written 82000 / 500000\n",
      "Written 83000 / 500000\n",
      "Written 84000 / 500000\n",
      "Written 85000 / 500000\n",
      "Written 86000 / 500000\n",
      "Written 87000 / 500000\n",
      "Written 88000 / 500000\n",
      "Written 89000 / 500000\n",
      "Written 90000 / 500000\n",
      "Written 91000 / 500000\n",
      "Written 92000 / 500000\n",
      "Written 93000 / 500000\n",
      "Written 94000 / 500000\n",
      "Written 95000 / 500000\n",
      "Written 96000 / 500000\n",
      "Written 97000 / 500000\n",
      "Written 98000 / 500000\n",
      "Written 99000 / 500000\n",
      "Written 100000 / 500000\n",
      "Written 101000 / 500000\n",
      "Written 102000 / 500000\n",
      "Written 103000 / 500000\n",
      "Written 104000 / 500000\n",
      "Written 105000 / 500000\n",
      "Written 106000 / 500000\n",
      "Written 107000 / 500000\n",
      "Written 108000 / 500000\n",
      "Written 109000 / 500000\n",
      "Written 110000 / 500000\n",
      "Written 111000 / 500000\n",
      "Written 112000 / 500000\n",
      "Written 113000 / 500000\n",
      "Written 114000 / 500000\n",
      "Written 115000 / 500000\n",
      "Written 116000 / 500000\n",
      "Written 117000 / 500000\n",
      "Written 118000 / 500000\n",
      "Written 119000 / 500000\n",
      "Written 120000 / 500000\n",
      "Written 121000 / 500000\n",
      "Written 122000 / 500000\n",
      "Written 123000 / 500000\n",
      "Written 124000 / 500000\n",
      "Written 125000 / 500000\n",
      "Written 126000 / 500000\n",
      "Written 127000 / 500000\n",
      "Written 128000 / 500000\n",
      "Written 129000 / 500000\n",
      "Written 130000 / 500000\n",
      "Written 131000 / 500000\n",
      "Written 132000 / 500000\n",
      "Written 133000 / 500000\n",
      "Written 134000 / 500000\n",
      "Written 135000 / 500000\n",
      "Written 136000 / 500000\n",
      "Written 137000 / 500000\n",
      "Written 138000 / 500000\n",
      "Written 139000 / 500000\n",
      "Written 140000 / 500000\n",
      "Written 141000 / 500000\n",
      "Written 142000 / 500000\n",
      "Written 143000 / 500000\n",
      "Written 144000 / 500000\n",
      "Written 145000 / 500000\n",
      "Written 146000 / 500000\n",
      "Written 147000 / 500000\n",
      "Written 148000 / 500000\n",
      "Written 149000 / 500000\n",
      "Written 150000 / 500000\n",
      "Written 151000 / 500000\n",
      "Written 152000 / 500000\n",
      "Written 153000 / 500000\n",
      "Written 154000 / 500000\n",
      "Written 155000 / 500000\n",
      "Written 156000 / 500000\n",
      "Written 157000 / 500000\n",
      "Written 158000 / 500000\n",
      "Written 159000 / 500000\n",
      "Written 160000 / 500000\n",
      "Written 161000 / 500000\n",
      "Written 162000 / 500000\n",
      "Written 163000 / 500000\n",
      "Written 164000 / 500000\n",
      "Written 165000 / 500000\n",
      "Written 166000 / 500000\n",
      "Written 167000 / 500000\n",
      "Written 168000 / 500000\n",
      "Written 169000 / 500000\n",
      "Written 170000 / 500000\n",
      "Written 171000 / 500000\n",
      "Written 172000 / 500000\n",
      "Written 173000 / 500000\n",
      "Written 174000 / 500000\n",
      "Written 175000 / 500000\n",
      "Written 176000 / 500000\n",
      "Written 177000 / 500000\n",
      "Written 178000 / 500000\n",
      "Written 179000 / 500000\n",
      "Written 180000 / 500000\n",
      "Written 181000 / 500000\n",
      "Written 182000 / 500000\n",
      "Written 183000 / 500000\n",
      "Written 184000 / 500000\n",
      "Written 185000 / 500000\n",
      "Written 186000 / 500000\n",
      "Written 187000 / 500000\n",
      "Written 188000 / 500000\n",
      "Written 189000 / 500000\n",
      "Written 190000 / 500000\n",
      "Written 191000 / 500000\n",
      "Written 192000 / 500000\n",
      "Written 193000 / 500000\n",
      "Written 194000 / 500000\n",
      "Written 195000 / 500000\n",
      "Written 196000 / 500000\n",
      "Written 197000 / 500000\n",
      "Written 198000 / 500000\n",
      "Written 199000 / 500000\n",
      "Written 200000 / 500000\n",
      "Written 201000 / 500000\n",
      "Written 202000 / 500000\n",
      "Written 203000 / 500000\n",
      "Written 204000 / 500000\n",
      "Written 205000 / 500000\n",
      "Written 206000 / 500000\n",
      "Written 207000 / 500000\n",
      "Written 208000 / 500000\n",
      "Written 209000 / 500000\n",
      "Written 210000 / 500000\n",
      "Written 211000 / 500000\n",
      "Written 212000 / 500000\n",
      "Written 213000 / 500000\n",
      "Written 214000 / 500000\n",
      "Written 215000 / 500000\n",
      "Written 216000 / 500000\n",
      "Written 217000 / 500000\n",
      "Written 218000 / 500000\n",
      "Written 219000 / 500000\n",
      "Written 220000 / 500000\n",
      "Written 221000 / 500000\n",
      "Written 222000 / 500000\n",
      "Written 223000 / 500000\n",
      "Written 224000 / 500000\n",
      "Written 225000 / 500000\n",
      "Written 226000 / 500000\n",
      "Written 227000 / 500000\n",
      "Written 228000 / 500000\n",
      "Written 229000 / 500000\n",
      "Written 230000 / 500000\n",
      "Written 231000 / 500000\n",
      "Written 232000 / 500000\n",
      "Written 233000 / 500000\n",
      "Written 234000 / 500000\n",
      "Written 235000 / 500000\n",
      "Written 236000 / 500000\n",
      "Written 237000 / 500000\n",
      "Written 238000 / 500000\n",
      "Written 239000 / 500000\n",
      "Written 240000 / 500000\n",
      "Written 241000 / 500000\n",
      "Written 242000 / 500000\n",
      "Written 243000 / 500000\n",
      "Written 244000 / 500000\n",
      "Written 245000 / 500000\n",
      "Written 246000 / 500000\n",
      "Written 247000 / 500000\n",
      "Written 248000 / 500000\n",
      "Written 249000 / 500000\n",
      "Written 250000 / 500000\n",
      "Written 251000 / 500000\n",
      "Written 252000 / 500000\n",
      "Written 253000 / 500000\n",
      "Written 254000 / 500000\n",
      "Written 255000 / 500000\n",
      "Written 256000 / 500000\n",
      "Written 257000 / 500000\n",
      "Written 258000 / 500000\n",
      "Written 259000 / 500000\n",
      "Written 260000 / 500000\n",
      "Written 261000 / 500000\n",
      "Written 262000 / 500000\n",
      "Written 263000 / 500000\n",
      "Written 264000 / 500000\n",
      "Written 265000 / 500000\n",
      "Written 266000 / 500000\n",
      "Written 267000 / 500000\n",
      "Written 268000 / 500000\n",
      "Written 269000 / 500000\n",
      "Written 270000 / 500000\n",
      "Written 271000 / 500000\n",
      "Written 272000 / 500000\n",
      "Written 273000 / 500000\n",
      "Written 274000 / 500000\n",
      "Written 275000 / 500000\n",
      "Written 276000 / 500000\n",
      "Written 277000 / 500000\n",
      "Written 278000 / 500000\n",
      "Written 279000 / 500000\n",
      "Written 280000 / 500000\n",
      "Written 281000 / 500000\n",
      "Written 282000 / 500000\n",
      "Written 283000 / 500000\n",
      "Written 284000 / 500000\n",
      "Written 285000 / 500000\n",
      "Written 286000 / 500000\n",
      "Written 287000 / 500000\n",
      "Written 288000 / 500000\n",
      "Written 289000 / 500000\n",
      "Written 290000 / 500000\n",
      "Written 291000 / 500000\n",
      "Written 292000 / 500000\n",
      "Written 293000 / 500000\n",
      "Written 294000 / 500000\n",
      "Written 295000 / 500000\n",
      "Written 296000 / 500000\n",
      "Written 297000 / 500000\n",
      "Written 298000 / 500000\n",
      "Written 299000 / 500000\n",
      "Written 300000 / 500000\n",
      "Written 301000 / 500000\n",
      "Written 302000 / 500000\n",
      "Written 303000 / 500000\n",
      "Written 304000 / 500000\n",
      "Written 305000 / 500000\n",
      "Written 306000 / 500000\n",
      "Written 307000 / 500000\n",
      "Written 308000 / 500000\n",
      "Written 309000 / 500000\n",
      "Written 310000 / 500000\n",
      "Written 311000 / 500000\n",
      "Written 312000 / 500000\n",
      "Written 313000 / 500000\n",
      "Written 314000 / 500000\n",
      "Written 315000 / 500000\n",
      "Written 316000 / 500000\n",
      "Written 317000 / 500000\n",
      "Written 318000 / 500000\n",
      "Written 319000 / 500000\n",
      "Written 320000 / 500000\n",
      "Written 321000 / 500000\n",
      "Written 322000 / 500000\n",
      "Written 323000 / 500000\n",
      "Written 324000 / 500000\n",
      "Written 325000 / 500000\n",
      "Written 326000 / 500000\n",
      "Written 327000 / 500000\n",
      "Written 328000 / 500000\n",
      "Written 329000 / 500000\n",
      "Written 330000 / 500000\n",
      "Written 331000 / 500000\n",
      "Written 332000 / 500000\n",
      "Written 333000 / 500000\n",
      "Written 334000 / 500000\n",
      "Written 335000 / 500000\n",
      "Written 336000 / 500000\n",
      "Written 337000 / 500000\n",
      "Written 338000 / 500000\n",
      "Written 339000 / 500000\n",
      "Written 340000 / 500000\n",
      "Written 341000 / 500000\n",
      "Written 342000 / 500000\n",
      "Written 343000 / 500000\n",
      "Written 344000 / 500000\n",
      "Written 345000 / 500000\n",
      "Written 346000 / 500000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written 347000 / 500000\n",
      "Written 348000 / 500000\n",
      "Written 349000 / 500000\n",
      "Written 350000 / 500000\n",
      "Written 351000 / 500000\n",
      "Written 352000 / 500000\n",
      "Written 353000 / 500000\n",
      "Written 354000 / 500000\n",
      "Written 355000 / 500000\n",
      "Written 356000 / 500000\n",
      "Written 357000 / 500000\n",
      "Written 358000 / 500000\n",
      "Written 359000 / 500000\n",
      "Written 360000 / 500000\n",
      "Written 361000 / 500000\n",
      "Written 362000 / 500000\n",
      "Written 363000 / 500000\n",
      "Written 364000 / 500000\n",
      "Written 365000 / 500000\n",
      "Written 366000 / 500000\n",
      "Written 367000 / 500000\n",
      "Written 368000 / 500000\n",
      "Written 369000 / 500000\n",
      "Written 370000 / 500000\n",
      "Written 371000 / 500000\n",
      "Written 372000 / 500000\n",
      "Written 373000 / 500000\n",
      "Written 374000 / 500000\n",
      "Written 375000 / 500000\n",
      "Written 376000 / 500000\n",
      "Written 377000 / 500000\n",
      "Written 378000 / 500000\n",
      "Written 379000 / 500000\n",
      "Written 380000 / 500000\n",
      "Written 381000 / 500000\n",
      "Written 382000 / 500000\n",
      "Written 383000 / 500000\n",
      "Written 384000 / 500000\n",
      "Written 385000 / 500000\n",
      "Written 386000 / 500000\n",
      "Written 387000 / 500000\n",
      "Written 388000 / 500000\n",
      "Written 389000 / 500000\n",
      "Written 390000 / 500000\n",
      "Written 391000 / 500000\n",
      "Written 392000 / 500000\n",
      "Written 393000 / 500000\n",
      "Written 394000 / 500000\n",
      "Written 395000 / 500000\n",
      "Written 396000 / 500000\n",
      "Written 397000 / 500000\n",
      "Written 398000 / 500000\n",
      "Written 399000 / 500000\n",
      "Written 400000 / 500000\n",
      "Written 401000 / 500000\n",
      "Written 402000 / 500000\n",
      "Written 403000 / 500000\n",
      "Written 404000 / 500000\n",
      "Written 405000 / 500000\n",
      "Written 406000 / 500000\n",
      "Written 407000 / 500000\n",
      "Written 408000 / 500000\n",
      "Written 409000 / 500000\n",
      "Written 410000 / 500000\n",
      "Written 411000 / 500000\n",
      "Written 412000 / 500000\n",
      "Written 413000 / 500000\n",
      "Written 414000 / 500000\n",
      "Written 415000 / 500000\n",
      "Written 416000 / 500000\n",
      "Written 417000 / 500000\n",
      "Written 418000 / 500000\n",
      "Written 419000 / 500000\n",
      "Written 420000 / 500000\n",
      "Written 421000 / 500000\n",
      "Written 422000 / 500000\n",
      "Written 423000 / 500000\n",
      "Written 424000 / 500000\n",
      "Written 425000 / 500000\n",
      "Written 426000 / 500000\n",
      "Written 427000 / 500000\n",
      "Written 428000 / 500000\n",
      "Written 429000 / 500000\n",
      "Written 430000 / 500000\n",
      "Written 431000 / 500000\n",
      "Written 432000 / 500000\n",
      "Written 433000 / 500000\n",
      "Written 434000 / 500000\n",
      "Written 435000 / 500000\n",
      "Written 436000 / 500000\n",
      "Written 437000 / 500000\n",
      "Written 438000 / 500000\n",
      "Written 439000 / 500000\n",
      "Written 440000 / 500000\n",
      "Written 441000 / 500000\n",
      "Written 442000 / 500000\n",
      "Written 443000 / 500000\n",
      "Written 444000 / 500000\n",
      "Written 445000 / 500000\n",
      "Written 446000 / 500000\n",
      "Written 447000 / 500000\n",
      "Written 448000 / 500000\n",
      "Written 449000 / 500000\n",
      "Written 450000 / 500000\n",
      "Written 451000 / 500000\n",
      "Written 452000 / 500000\n",
      "Written 453000 / 500000\n",
      "Written 454000 / 500000\n",
      "Written 455000 / 500000\n",
      "Written 456000 / 500000\n",
      "Written 457000 / 500000\n",
      "Written 458000 / 500000\n",
      "Written 459000 / 500000\n",
      "Written 460000 / 500000\n",
      "Written 461000 / 500000\n",
      "Written 462000 / 500000\n",
      "Written 463000 / 500000\n",
      "Written 464000 / 500000\n",
      "Written 465000 / 500000\n",
      "Written 466000 / 500000\n",
      "Written 467000 / 500000\n",
      "Written 468000 / 500000\n",
      "Written 469000 / 500000\n",
      "Written 470000 / 500000\n",
      "Written 471000 / 500000\n",
      "Written 472000 / 500000\n",
      "Written 473000 / 500000\n",
      "Written 474000 / 500000\n",
      "Written 475000 / 500000\n",
      "Written 476000 / 500000\n",
      "Written 477000 / 500000\n",
      "Written 478000 / 500000\n",
      "Written 479000 / 500000\n",
      "Written 480000 / 500000\n",
      "Written 481000 / 500000\n",
      "Written 482000 / 500000\n",
      "Written 483000 / 500000\n",
      "Written 484000 / 500000\n",
      "Written 485000 / 500000\n",
      "Written 486000 / 500000\n",
      "Written 487000 / 500000\n",
      "Written 488000 / 500000\n",
      "Written 489000 / 500000\n",
      "Written 490000 / 500000\n",
      "Written 491000 / 500000\n",
      "Written 492000 / 500000\n",
      "Written 493000 / 500000\n",
      "Written 494000 / 500000\n",
      "Written 495000 / 500000\n",
      "Written 496000 / 500000\n",
      "Written 497000 / 500000\n",
      "Written 498000 / 500000\n",
      "Written 499000 / 500000\n",
      "Written 500000 / 500000\n",
      "Created dataset with 500000 samples\n",
      "Written 1000 / 10000\n",
      "Written 2000 / 10000\n",
      "Written 3000 / 10000\n",
      "Written 4000 / 10000\n",
      "Written 5000 / 10000\n",
      "Written 6000 / 10000\n",
      "Written 7000 / 10000\n",
      "Written 8000 / 10000\n",
      "Written 9000 / 10000\n",
      "Written 10000 / 10000\n",
      "Created dataset with 10000 samples\n"
     ]
    }
   ],
   "source": [
    "output_image_folder = '/media/mehdi2277/MyFiles/large_datasets/text_classification/produced_words'\n",
    "sanborn_dataset = TextDataset(use_word_dictionary, mixed_sanborn_words, \n",
    "                              number_of_training_data_points = 500000,\n",
    "                              number_of_validation_data_points = 10000,\n",
    "                              number_prob=0.5, deskewed=False, noise=False)\n",
    "database_path = '/media/mehdi2277/MyFiles/large_datasets/text_classification/lmdb_files/mixed_sanborn_word_training'\n",
    "sanborn_dataset.generate_words(output_image_folder, database_path, training=True)\n",
    "database_path = '/media/mehdi2277/MyFiles/large_datasets/text_classification/lmdb_files/mixed_sanborn_word_validation'\n",
    "sanborn_dataset.generate_words(output_image_folder, database_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "notify_time": "30"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
