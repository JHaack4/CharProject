{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "import json\n",
    "\n",
    "import create_dataset\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_loader(path):\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            with Image.open(f) as img:\n",
    "                return img.convert('L')\n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(data.Dataset):\n",
    "    def __init__(self, word_dictionary, image_folder, image_folder_names, image_transform,\n",
    "                 number_of_data_points=50000, minimum_number=1, maximum_number=100000, \n",
    "                 character_rotation_prob=0.3, word_rotation_prob=0.7,\n",
    "                 minimum_character_rotation_angle=-5,\n",
    "                 maximum_character_rotation_angle=5,\n",
    "                 minimum_word_rotation_angle = -15,\n",
    "                 maximum_word_rotation_angle = 15,\n",
    "                 number_prob=1, \n",
    "                 minimum_digit_spacing=0, minimum_word_spacing=1, \n",
    "                 maximum_digit_spacing=1, maximum_word_spacing=4,\n",
    "                 maximum_vertical_padding=4,\n",
    "                 seed=1000):\n",
    "        self.img_paths = []\n",
    "        self.all_img_paths = []\n",
    "        self.labels = []\n",
    "        self.text_labels = []\n",
    "        self.is_digit = []\n",
    "        \n",
    "        for image_folder_name in image_folder_names:\n",
    "            image_path = os.path.expanduser(os.path.join(image_folder, image_folder_name))\n",
    "            self.all_img_paths.append(list(map(lambda file: os.path.join(image_path, file), \n",
    "                                               os.listdir(image_path))))\n",
    "                        \n",
    "        for i in range(number_of_data_points):\n",
    "            self.img_paths.append([])\n",
    "            self.labels.append([])\n",
    "            self.is_digit.append(True)\n",
    "            \n",
    "            if random.random() < number_prob:\n",
    "                number = random.randrange(minimum_number, maximum_number)\n",
    "                self.text_labels.append(str(number))\n",
    "                \n",
    "                for digit in str(number):\n",
    "                    self.labels[i].append(int(digit))\n",
    "                    randChoice = random.choice(self.all_img_paths[int(digit)])\n",
    "                    while (randChoice[-4:] != '.png'):\n",
    "                        randChoice = random.choice(self.all_img_paths[int(digit)])\n",
    "                    self.img_paths[i].append(randChoice)\n",
    "            else:\n",
    "                self.is_digit.append(False)\n",
    "                word = random.choice(word_dictionary)\n",
    "                self.text_labels.append(word)\n",
    "                                \n",
    "                for char in word:\n",
    "                    ascii_code = ord(char)\n",
    "                    \n",
    "                    if ascii_code < 65:\n",
    "                        ascii_code -= 48\n",
    "                    else:\n",
    "                        ascii_code -= 55\n",
    "                    \n",
    "                    self.labels[i].append(ascii_code)\n",
    "                    self.img_paths[i].append(random.choice(self.all_img_paths[ascii_code]))\n",
    "        \n",
    "        self.image_transform = image_transform\n",
    "        self.character_rotation_prob = character_rotation_prob\n",
    "        self.word_rotation_prob = word_rotation_prob\n",
    "        self.minimum_character_rotation_angle = minimum_character_rotation_angle\n",
    "        self.maximum_character_rotation_angle = maximum_character_rotation_angle\n",
    "        self.minimum_word_rotation_angle = minimum_word_rotation_angle\n",
    "        self.maximum_word_rotation_angle = maximum_word_rotation_angle\n",
    "        self.minimum_digit_spacing = minimum_digit_spacing\n",
    "        self.maximum_digit_spacing = maximum_digit_spacing\n",
    "        self.minimum_word_spacing = minimum_word_spacing\n",
    "        self.maximum_word_spacing = maximum_word_spacing\n",
    "        self.maximum_vertical_padding = maximum_vertical_padding\n",
    "        self.seed = seed\n",
    "        self.reset_seed()\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        vertical_pad = random.randrange(0, self.maximum_vertical_padding)\n",
    "        \n",
    "        if random.random() < self.character_rotation_prob:\n",
    "            angle = random.randrange(self.minimum_character_rotation_angle, \n",
    "                                     self.maximum_character_rotation_angle)\n",
    "            \n",
    "            full_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "#                 transforms.Lambda(lambda img: 1 - img),\n",
    "                transforms.Lambda(lambda img: tensor_rotate_bound(angle, img)),\n",
    "                self.image_transform,\n",
    "                transforms.Pad((0, vertical_pad))\n",
    "            ])  \n",
    "        else:\n",
    "            full_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "#                 transforms.Lambda(lambda img: 1 - img),\n",
    "                self.image_transform,\n",
    "                transforms.Pad((0, vertical_pad))\n",
    "            ])\n",
    "        \n",
    "        images = []\n",
    "        \n",
    "        for image_path in self.img_paths[i]:\n",
    "            image = pil_loader(image_path)\n",
    "            image = full_transform(image)\n",
    "            \n",
    "            if self.is_digit[i]:\n",
    "                right_pad = random.randrange(self.minimum_digit_spacing, self.maximum_digit_spacing)\n",
    "            else:\n",
    "                right_pad = random.randrange(self.minimum_word_spacing, self.maximum_word_spacing)\n",
    "            \n",
    "            image = transforms.ToTensor()(transforms.Pad((0, 0, right_pad, 0))(image))\n",
    "            images.append(image)\n",
    "        \n",
    "        full_image = torch.cat(images, dim=2)\n",
    "        _, height, _ = full_image.size()\n",
    "        \n",
    "        if self.is_digit[i]:\n",
    "            left_pad = random.randrange(0, self.maximum_digit_spacing)\n",
    "        else:\n",
    "            left_pad = random.randrange(0, self.maximum_word_spacing)\n",
    "        \n",
    "        if left_pad != 0:\n",
    "            padding = torch.zeros(1, height, left_pad)\n",
    "            full_image = torch.cat((padding, full_image), dim=2)\n",
    "        \n",
    "        \n",
    "        if random.random() < self.word_rotation_prob:\n",
    "            angle = random.randrange(self.minimum_word_rotation_angle, \n",
    "                                     self.maximum_word_rotation_angle)\n",
    "            full_image = tensor_rotate_bound(angle, full_image)\n",
    "        \n",
    "        full_image = vertical_scale_preserve_aspect_ratio(transforms.ToPILImage()(full_image))\n",
    "        full_image = transforms.ToTensor()(full_image)\n",
    "        return full_image, torch.LongTensor(self.labels[i])\n",
    "    \n",
    "    def reset_seed(self):\n",
    "        random.seed(self.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertical_scale_preserve_aspect_ratio(img, height=32):\n",
    "    w, h = img.size\n",
    "    \n",
    "    return transforms.Resize((height,int(height/h * w)), interpolation=Image.BICUBIC)(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tightest_image_crop(img, preserve_aspect_ratio=False):\n",
    "    image_indices = F.threshold(Variable(img[0]), 0.0000001, 0).data.nonzero()\n",
    "    top_i = image_indices[0,0]\n",
    "    bottom_i = image_indices[-1,0]\n",
    "    \n",
    "    mins, _ = image_indices.min(dim=0)\n",
    "    left_i = mins[1]\n",
    "    \n",
    "    maxs, _ = image_indices.max(dim=0)\n",
    "    right_i = maxs[1]\n",
    "    \n",
    "    new_width = right_i-left_i+1\n",
    "    new_height = top_i-bottom_i+1\n",
    "        \n",
    "    if preserve_aspect_ratio:\n",
    "        if new_width > new_height:\n",
    "            result = img[:, top_i:top_i+new_width, left_i:right_i+1]\n",
    "            show(result)\n",
    "            plt.show()\n",
    "            return img[:, top_i:top_i+new_width, left_i:right_i+1]\n",
    "        else:\n",
    "            result = img[:, top_i:bottom_i+1, left_i:left_i+new_height]\n",
    "            show(result)\n",
    "            plt.show()\n",
    "            return img[:, top_i:bottom_i+1, left_i:left_i+new_height]\n",
    "        \n",
    "    return img[:, top_i:bottom_i+1, left_i:right_i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_rotate_bound(angle, tensor):\n",
    "    return torch.Tensor(rotate_bound(tensor.permute(1,2,0).numpy(), angle)).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is taken from https://www.pyimagesearch.com/2017/01/02/rotate-images-correctly-with-opencv-and-python/\n",
    "# which is from imutils and that uses the MIT License. The author of this code is Adrian Rosebrock.\n",
    "def rotate_bound(image, angle):\n",
    "    # grab the dimensions of the image and then determine the\n",
    "    # center\n",
    "    (h, w) = image.shape[:2]\n",
    "    (cX, cY) = (w // 2, h // 2)\n",
    " \n",
    "    # grab the rotation matrix (applying the negative of the\n",
    "    # angle to rotate clockwise), then grab the sine and cosine\n",
    "    # (i.e., the rotation components of the matrix)\n",
    "    M = cv2.getRotationMatrix2D((cX, cY), -angle, 1.0)\n",
    "    cos = np.abs(M[0, 0])\n",
    "    sin = np.abs(M[0, 1])\n",
    " \n",
    "    # compute the new bounding dimensions of the image\n",
    "    nW = int((h * sin) + (w * cos))\n",
    "    nH = int((h * cos) + (w * sin))\n",
    " \n",
    "    # adjust the rotation matrix to take into account translation\n",
    "    M[0, 2] += (nW / 2) - cX\n",
    "    M[1, 2] += (nH / 2) - cY\n",
    " \n",
    "    # perform the actual rotation and return the image\n",
    "    return cv2.warpAffine(image, M, (nW, nH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Lambda(tightest_image_crop),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Lambda(vertical_scale_preserve_aspect_ratio)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    npimg = img.numpy()[0]\n",
    "    plt.figure()\n",
    "    plt.imshow(npimg, interpolation='nearest', cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder_names = [digit for digit in '0123456789']\n",
    "image_folder = \"/media/mehdi2277/MyFiles/large_datasets/text_classification/SanbornDigits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_datapoints = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_images = TextDataset({}, image_folder, image_folder_names, \n",
    "                          transform, number_of_data_points=num_datapoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_images.reset_seed()\n",
    "word_images_by_width_index = sorted(range(len(word_images)), key=lambda i: word_images[i][0].size()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = '/media/mehdi2277/MyFiles/large_datasets/text_classification/produced_words'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n"
     ]
    }
   ],
   "source": [
    "word_images.reset_seed()\n",
    "text_labels_by_width = []\n",
    "\n",
    "for progress_index, index in enumerate(word_images_by_width_index):\n",
    "    if progress_index % 1000 == 0:\n",
    "        print(progress_index)\n",
    "    \n",
    "    datapoint, label = word_images[index]\n",
    "    image = transforms.ToPILImage()(datapoint)\n",
    "    image_name = str(progress_index) + '.png'\n",
    "    image_path = os.path.join(image_directory, image_name)\n",
    "    image.save(image_path)\n",
    "    text_labels_by_width.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_labels_by_width = list(map(list, text_labels_by_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_character(index):\n",
    "    if index < 10:\n",
    "        return chr(ord('0') + index)\n",
    "    else:\n",
    "        return chr(ord('A') + (index - 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_labels_by_width = list(map(lambda word: \"\".join(map(index_to_character, word)), text_labels_by_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_labels_file_name = 'text_labels_training.json'\n",
    "# text_labels_file_handle = open(image_directory + text_labels_file_name, 'w')\n",
    "# json.dump(text_labels_by_width, text_labels_file_handle)\n",
    "# text_labels_file_handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = list(map(lambda n: os.path.join(image_directory, str(n) + \".png\"), range(num_datapoints)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_file_name = '/media/mehdi2277/MyFiles/large_datasets/text_classification/lmdb_files/number_images_sanborn_all_validation.mdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written 1000 / 10000\n",
      "Written 2000 / 10000\n",
      "Written 3000 / 10000\n",
      "Written 4000 / 10000\n",
      "Written 5000 / 10000\n",
      "Written 6000 / 10000\n",
      "Written 7000 / 10000\n",
      "Written 8000 / 10000\n",
      "Written 9000 / 10000\n",
      "Written 10000 / 10000\n",
      "Created dataset with 10000 samples\n"
     ]
    }
   ],
   "source": [
    "create_dataset.createDataset(database_file_name, image_paths, text_labels_by_width)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
